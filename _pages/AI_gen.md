---
layout: archive
title: "AI powered heritage restoration"
permalink: AI_gen/
author_profile: true
---


{% include base_path %}

Analagous to the explosion of "intelligence" in LLMs that seemed to be an emergent feature of word association, an understanding of mechanical and physical parameterisation seems to be a side product of training vision-based generative models which pixels go together well. I'm fascinated by interrogating whatever implicit knowledge of physical properties and permanence that generative models have gleaned from this process.

Some selected AI generations from my work

As part of my projects working with embroidered artwork interpretation for visually impaired people, I am training diffusion models to generate art in the same style as the source. This can be used to generate complete objects that are obscured in the original artefact (for example, an item of fureniture that is not completely visible because someone is sitting on it), and also to make "repairs" on digital versions of an artwork. Like most generative AI, it's also just good fun.

Teaching Flux-dev-1 the french knot embroidery technique:

<img src="/images/man_chess_park.gif" style="height:450px;">
<img src="/images/bear_house_snow.gif" style="height:450px;">
<img src="/images/man_sign.gif" style="height:450px;">
<img src="/images/woman_desk_lightning.gif" style="height:450px;">

And to make a "repair" to artwork:

<img src="/images/stitch_repair.mp4" style="height:450px;">

I followed [this walkthrough](https://www.stablediffusiontutorials.com/2024/08/flux-lora.html#downloading-the-models) for the guide to train a Lora.


